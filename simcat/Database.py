#!/usr/bin/env python

"""
Generate a large database ...
"""

# imports for py3 compatibility
from __future__ import print_function
from builtins import range

import os
import h5py
import time

import toytree
import numpy as np
import itertools as itt
from scipy.special import comb

from .Model import Model
from .Simulator import Simulator
from .parallel import Parallel
from .utils import get_all_admix_edges, SimcatError, progress_bar


############################################################################
class Database:
    """
    An object to build a HD5 database with parameters (labels) for simulations.
    The number of labeled tests is equal to nevents * ntests * nreps, 
    where nevents is based on the tree topology and number of admixture edges 
    drawn on it (nedges). Typical use is to provide a fixed ultrametric tree
    and build the database for all placements of one or two admixture edges 
    on the tree. 

    Parameters:
    -----------
    name: str
        The name that will be used in the saved database file (<name>.hdf5)

    workdir: str
        The location where the database file will be saved, or loaded from 
        if continuing an analysis from a checkpoint. 

    tree: newick or toytree
        A fixed topology to use for all simulations. Edge lengths are fixed
        unless the argument 'edge_function' is used, in which case edge lengths 
        are drawn from a distribution.

    nedges: int (default=0)
        The number of admixture edges to add to each tree at a time. All edges
        will be drawn on the tree that can connect any branches which overlap 
        for a nonzero amount of time. A set of admixture scenarios 
        generated by drawing nedges on a tree is referred to as nevents, and 
        all possible events will be tested. 
        * Each nedge increases nvalues by nevents * ntests * nreps. 

    ntests: int (default=100)
        The number of parameters to draw for each admixture_event described
        by an edge but sampling different durations, magnitudes, and mutation
        rates (theta). For example, (2, 1, None, None, None) could draw 
        (2, 1, 0.1, 0.3, 0.01) and theta=0.1 in one randomly drawn test, 
        and (2, 1, 0.2, 0.4, 0.02) and theta=0.2 in another. 
        * Each ntest increases nvalues by nreps. 

    nreps: int (default=10)
        The number of replicate simulations to run per admixture scenario, 
        sampled tree, and parameter set (nevent, ntree, ntest). Replicate 
        simulations make identical calls to msprime but get variable result
        matrices due to variability in the coalescent process.

    nsnps: int (default=1000)
        The number of SNPs in each simulation that are used to build the 
        16x16 arrays of phylogenetic invariants for each quartet sample. 

    theta: int or tuple (default=0.01)
        The mutation parameter (2*Ne*u), or range of values from which values
        will be uniformly drawn across ntests. 

    seed: int (default=123)
        Set the seed of the random number generator

    force: bool (default=False)
        Force overwrite of existing database file.
    """
    def __init__(
        self,
        name,
        workdir,
        tree,
        nsnps=10000,
        nedges=0,
        ntests=1,
        nreps=1,
        theta=0.01,
        seed=123,
        admix_lower=0.5, 
        admix_upper=0.5,
        force=False,
        quiet=False,
        ):

        # database locations
        self.name = name
        self.workdir = (
            workdir if workdir 
            else os.path.realpath(os.path.join('.', "databases")))
        self.database = os.path.realpath(
            os.path.join(workdir, self.name + ".hdf5"))
        self.checkpoint = 0
        self._db = None  # open/closed file handle of self.database
        self._quiet = quiet

        # store params
        self.theta = theta
        self.tree = (
            toytree.tree(tree) if isinstance(tree, str) else tree.copy())
        self.lower = admix_lower
        self.upper = admix_upper

        # database label combinations
        self.nedges = nedges
        self.ntests = ntests        
        self.nreps = nreps
        self.nsnps = nsnps
        self.nstored_values = None

        # decide on an appropriate chunksize to keep memory load reasonable
        self.chunksize = 100

        # store ipcluster information 
        self.ipcluster = {
            "cluster_id": "", 
            "profile": "default",
            "engines": "Local", 
            "quiet": 0, 
            "timeout": 60, 
            "cores": 0, 
            "threads": 2,
            "pids": {},
        }

        # make sure workdir exists
        if not os.path.exists(workdir):
            os.makedirs(workdir)


    def debug_report(self):
        """
        Prints to screen info about the size of the database
        Assumes the self._db handle is open in read-mode
        """
        keys = self._db.keys()
        for key in keys:
            print(key, self._db[key].shape)


    def _generate_empty_database(self):
        """
        Parses parameters in self.params to create all combinations
        of parameter values to test. Returns the number of the simulations.
        Simulation metadata is appended to datasets. 

        Expect that the h5 file self._db is open in w or a mode.
        """       
        # store the tree as newick using idx for name, 
        storetree = self.tree.copy()
        for node in storetree.treenode.traverse():
            node.name = node.idx
        self._db.attrs["tree"] = storetree.write()
        self._db.attrs["nsnps"] = self.nsnps

        # data size = nevents x ntests x nreps
        admixedges = get_all_admix_edges(storetree)
        nevents = int(comb(N=len(admixedges), k=self.nedges))
        nvalues = nevents * self.ntests * self.nreps 
        self.nstored_values = nvalues

        # number of quartets depends only on size of tree
        nquarts = int(comb(N=len(storetree), k=4))

        # store count matrices (the data)
        self._db.create_dataset("counts", 
            shape=(nvalues, nquarts, 16, 16),
            dtype=np.float32)

        # the labels: for pulsed migration admix_tstarts but not admix_tends
        self._db.create_dataset("admix_sources", 
            shape=(nvalues, self.nedges),
            dtype=np.uint8)
        self._db.create_dataset("admix_targets", 
            shape=(nvalues, self.nedges),
            dtype=np.uint8)
        self._db.create_dataset("admix_props", 
            shape=(nvalues, self.nedges),
            dtype=np.float64)
        self._db.create_dataset("admix_times", 
            shape=(nvalues, self.nedges),
            dtype=np.float64)
        # self._db.create_dataset("admix_tends", 
        # shape=(nvalues, self.nedges),
        # dtype=np.float64)

        # store parameters of the simulation
        self._db.create_dataset("thetas",
            shape=(nvalues,),
            dtype=np.float64)


    def fill_database_labels(self, force=False):
        """
        This is called by .run() automatically and not meant to be called by 
        users except for debugging purposes. This will create the database 
        (._db attribute) and fill it with labels. 

        This iterates across generated trees and creates simulation scenarios
        for nreps iterations for each admixture edge(s) scenario in the tree
        and stores the full parameter information into the hdf5 database.
        """

        # create database in 'w-' mode to prevent overwriting
        if os.path.exists(self.database):
            if force:
                os.remove(self.database)
                self._db = h5py.File(self.database, mode='w')
            # exists, append to it
            else:
                self._db = h5py.File(self.database, mode='a')
        else:
            # does not exist
            self._db = h5py.File(self.database, mode='w-')     

        # Create h5 datasets for these simulations
        if not self._db.get("counts"):
            self._generate_empty_database()

        # (1) ntrees: iterate over each sampled tree (itree)
        itree = self.tree

        # get all admixture edges that can be drawn on this tree
        admixedges = get_all_admix_edges(itree)

        # (2) nevents: iterate over each edge or pair of edges (nedges)        
        eidx = 0
        events = itt.combinations(admixedges.keys(), self.nedges)
        for evt in events:

            # tuple of admixture_edges
            admixlist = [
                (i[0], i[1], self.lower, self.upper, None) for i in evt
            ]

            # (3) ntests: sample duration, magnitude, and params on edges
            model = Model(
                tree=itree, 
                ntests=self.ntests,
                theta=self.theta,
                admixture_edges=admixlist,
            )

            # (4) nreps: fill the same param values repeated times
            mdict = model.test_values
            nnn = self.ntests * self.nreps
            sta, end = eidx, eidx + nnn

            # store thetas same for every rep, but not test (0,0,0,1,1,1)
            thetas = tile_reps(mdict["thetas"], self.nreps)
            self._db["thetas"][sta:end] = thetas

            # get labels from admixlist and model.test_values
            for xidx in range(model.aedges):
                sources = np.repeat(admixlist[xidx][0], nnn)
                targets = np.repeat(admixlist[xidx][1], nnn)
                mrates = tile_reps(mdict[xidx]["mrates"], self.nreps)
                mtimes = tile_reps(mdict[xidx]["mtimes"][:, 0], self.nreps)
                # mend = tile_reps(mdict[xidx]["mtimes"][:, 1], self.nreps)                    

                # store labels for this admix event (nevents x nreps)
                self._db["admix_sources"][sta:end, xidx] = sources
                self._db["admix_targets"][sta:end, xidx] = targets
                self._db["admix_props"][sta:end, xidx] = mrates
                self._db["admix_times"][sta:end, xidx] = mtimes.astype(np.float64)
                # self._db["admix_tstarts"][sta:end, xidx] = msta
                # self._db["admix_tends"][sta:end, xidx] = mend

            eidx += nnn

        # progress
        if not self._quiet:
            print("{} sims: {}".format(self.nstored_values, self.database))
              

    def _run(self, ipyclient):
        """
        Sends jobs to parallel engines to run Simulator.run().
        """
        # load-balancer for single-threaded execution jobs
        lbview = ipyclient.load_balanced_view()

        # set chunksize based on ncores and nstored_values
        ncores = len(ipyclient)
        nvals = self.nstored_values
        self.chunksize = int(np.ceil(nvals / (ncores * 4)))
        self.chunksize = min(1000, self.chunksize)
        self.chunksize = max(4, self.chunksize)        

        # an iterator to return chunked slices of jobs
        jobs = range(self.checkpoint, self.nstored_values, self.chunksize)
        njobs = int((self.nstored_values - self.checkpoint) / self.chunksize)

        # start progress bar
        start = time.time()

        # submit jobs to engines
        rasyncs = {}
        for job in jobs:
            args = (self.database, job, job + self.chunksize)
            rasyncs[job] = lbview.apply(Simulator, *args)

        # wait for jobs to finish, catch results as they return and enter 
        # them into the HDF5 database. This keeps memory low.
        done = self.checkpoint
        try:
            io5 = h5py.File(self.database, 'r+')
            while 1:
                ## gather finished jobs
                finished = [i for i, j in rasyncs.items() if j.ready()]

                ## iterate over finished list and insert results
                for job in finished:
                    rasync = rasyncs[job]
                    if rasync.successful():

                        # store result
                        done += 1
                        result = rasync.get().counts                       
                        io5["counts"][job:job + self.chunksize] = result

                        # free up memory from job
                        del rasyncs[job]

                    else:
                        raise SimcatError(rasync.get())

                # print progress
                progress_bar(njobs, done, start, "simulating count matrices")

                # finished: break loop
                if len(rasyncs) == 0:
                    break
                else:
                    time.sleep(0.5)
        finally:
            io5.close()


    def run(self, force=True, ipyclient=None, show_cluster=False, auto=False):
        """
        Distributes parallel jobs and wraps functions for convenient cleanup.
        Fills all count matrices with simulated data. 

        Parameters
        ----------
        ipyclient (ipyparallel.Client object):
            A connected ipyclient object. If ipcluster instance is 
            not running on the default profile then ...
        """
        # Fill all params into the database (this inits the Model objects 
        # which call ._get_test_values() to generate all simulation scenarios.
        self.fill_database_labels(force=force)

        # Close the database. It is now ready to be filled with .run()
        # which will run until all tests are finished in the database. We 
        # could then return to this Model object and add more tests later 
        # if we wanted by using ...<make this>
        self._db.close()

        # distribute filling jobs in parallel
        pool = Parallel(
            tool=self,
            rkwargs={},
            ipyclient=ipyclient,
            show_cluster=show_cluster,
            auto=auto,
            )
        pool.wrap_run()



def tile_reps(array, nreps):
    "used to fill labels in the simcat.Database for replicates"
    ts = array.size
    nr = nreps
    result = np.array(
        np.tile(array, nr)
        .reshape((nr, ts))
        .T.flatten())
    return result
